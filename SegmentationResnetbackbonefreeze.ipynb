{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aZRh9b3igIBn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import glob\n",
    "import datetime\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "%load_ext tensorboard\n",
    "\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from skimage import img_as_ubyte\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as keras\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.utils import normalize\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v70RWWv4gfcH",
    "outputId": "c32e5e5b-817f-4591-89f2-bb1b8846d4b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SM_FRAMEWORK=tf.keras\n"
     ]
    }
   ],
   "source": [
    "%env SM_FRAMEWORK=tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7GIXnMragfZm",
    "outputId": "3673f523-c626-4a80-dadc-a5861946fdf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "S3QCNdl3qhWF"
   },
   "outputs": [],
   "source": [
    "from segmentation_models.utils import set_trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2TaGFMG2gfTS"
   },
   "outputs": [],
   "source": [
    "# os.chdir('/content/drive/MyDrive/Dermatophyte/Segmentation/Data')\n",
    "#seed = 20\n",
    "#np.random.seed = seed\n",
    "\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "TRAIN_PATH = 'C:/Users/hanus/Desktop/Manipal/semester_2/CNN/project/segmentation/data/neutrophils/train/'\n",
    "TEST_PATH = 'C:/Users/hanus/Desktop/Manipal/semester_2/CNN/project/segmentation/data/neutrophils/test/'\n",
    "\n",
    "train_ids = os.listdir(TRAIN_PATH + 'image/')\n",
    "test_ids = os.listdir(TEST_PATH + 'image/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qa7N3sIzgk09",
    "outputId": "8d141ad6-8eca-4128-dc3a-383dc41bf8a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████▎                                                                                                                                                                    | 14/376 [00:00<00:02, 138.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images without ROI:  107\n",
      "Resizing training images and masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 376/376 [00:02<00:00, 164.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 122.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing test images and masks\n"
     ]
    }
   ],
   "source": [
    "# OneDrive_1_5-16-2021\n",
    "path_1 = \"C:/Users/hanus/Desktop/Manipal/semester_2/CNN/project/unet/unet/dup_data/neutrophils/OneDrive_1_5-16-2021/train/label/\"\n",
    "emp_img_list = []\n",
    "os.chdir(path_1)\n",
    "\n",
    "for filename in os.listdir(path_1):\n",
    "    img = imread(filename)\n",
    "    if np.sum(img) == 0:\n",
    "        emp_img_list.append(filename)\n",
    "print(\"Number of images without ROI: \", len(emp_img_list))\n",
    "\n",
    "# non_emp_img_list = []\n",
    "# for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "#     if id_ not in emp_img_list:\n",
    "#         non_emp_img_list.append(id_)\n",
    "\n",
    "os.chdir('C:/Users/hanus/Desktop/Manipal/semester_2/CNN/project/unet/unet/data')\n",
    "print('Resizing training images and masks')\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    if id_ not in emp_img_list:\n",
    "        img = imread(TRAIN_PATH + '/image/' + id_)\n",
    "        img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH), interpolation=cv2.INTER_NEAREST)\n",
    "        norm_img = np.zeros((800,800))\n",
    "        img = cv2.normalize(img, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "        X_train.append(img)\n",
    "        mask = imread(TRAIN_PATH + '/label/' + id_ )\n",
    "        mask = cv2.resize(mask, (IMG_HEIGHT, IMG_WIDTH), interpolation=cv2.INTER_NEAREST)\n",
    "        Y_train.append((mask[:,:,0] / 255).reshape(256, 256, 1))\n",
    "        \n",
    "print('Resizing test images and masks')\n",
    "X_test = []\n",
    "Y_test = []\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    if id_ not in emp_img_list:\n",
    "        img1 = imread(TEST_PATH + '/image/' + id_ )\n",
    "        img1 = cv2.resize(img1, (IMG_HEIGHT, IMG_WIDTH), interpolation=cv2.INTER_NEAREST)\n",
    "        X_test.append(img1)\n",
    "        mask1 = imread(TEST_PATH  + '/label/' + id_ )\n",
    "        mask1 = cv2.resize(mask1, (IMG_HEIGHT, IMG_WIDTH), interpolation=cv2.INTER_NEAREST)\n",
    "        Y_test.append((mask1[:,:,0] / 255).reshape(256, 256, 1))\n",
    "        \n",
    "X_train = np.array(X_train)/255\n",
    "Y_train = np.array(Y_train)\n",
    "X_test = np.array(X_test)/255\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes :\n",
      "======\n",
      "X_train = (269, 256, 256, 3)\n",
      "Y_train = (269, 256, 256, 1)\n",
      "X_test  = (11, 256, 256, 3)\n",
      "Y_test  = (11, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes :\\n======\\nX_train = {}\\nY_train = {}\\nX_test  = {}\\nY_test  = {}\"\n",
    "      .format(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BPs4-HZxqnQe"
   },
   "outputs": [],
   "source": [
    "BACKBONE = 'resnet34'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "# load your data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_val,y_train,y_val = train_test_split(X_train,  Y_train, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# preprocess input\n",
    "X_train = preprocess_input(x_train)\n",
    "X_val = preprocess_input(x_val)\n",
    "\n",
    "\n",
    "\n",
    "#logdir\n",
    "log_dir = \"logsfreez/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint('freez.h5', verbose=1, save_best_only=True)\n",
    "#earlystopper = tf.keras.callbacks.EarlyStopping(patience = 10, monitor='val_loss')\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "callbacks = [\n",
    "              checkpointer,\n",
    "              tensorboard\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "glmqruPigFBq",
    "outputId": "6cd0c781-4f5c-43ad-c01a-e5c303701915"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanus\\anaconda3\\envs\\CNN\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 34s 783ms/step - loss: 1.4354 - iou_score: 0.0553 - val_loss: 1.6045 - val_iou_score: 0.0679\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60446, saving model to freez.h5\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 3s 220ms/step - loss: 1.3504 - iou_score: 0.0652 - val_loss: 1.6177 - val_iou_score: 0.0680\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.60446\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 3s 219ms/step - loss: 1.2816 - iou_score: 0.0829 - val_loss: 1.6112 - val_iou_score: 0.0680\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.60446\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 3s 219ms/step - loss: 1.2217 - iou_score: 0.1045 - val_loss: 1.6131 - val_iou_score: 0.0680\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.60446\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 3s 220ms/step - loss: 1.1756 - iou_score: 0.1248 - val_loss: 1.6221 - val_iou_score: 0.0681\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.60446\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 3s 221ms/step - loss: 1.1377 - iou_score: 0.1420 - val_loss: 1.6316 - val_iou_score: 0.0682\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.60446\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 3s 219ms/step - loss: 1.1050 - iou_score: 0.1552 - val_loss: 1.6312 - val_iou_score: 0.0682\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.60446\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 3s 220ms/step - loss: 1.0775 - iou_score: 0.1660 - val_loss: 1.6260 - val_iou_score: 0.0682\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.60446\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 3s 219ms/step - loss: 1.0538 - iou_score: 0.1768 - val_loss: 1.6003 - val_iou_score: 0.0679\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.60446 to 1.60028, saving model to freez.h5\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 3s 217ms/step - loss: 1.0306 - iou_score: 0.1907 - val_loss: 1.5896 - val_iou_score: 0.0680\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.60028 to 1.58956, saving model to freez.h5\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = sm.Unet(BACKBONE,encoder_weights='imagenet',classes=1,activation='sigmoid', encoder_freeze = True, decoder_block_type='transpose')\n",
    "LR = 0.0001\n",
    "optim =tf.keras.optimizers.Adam(LR)\n",
    "model.compile(\n",
    "    optim,\n",
    "    loss=sm.losses.bce_jaccard_loss,\n",
    "    metrics=[sm.metrics.iou_score],\n",
    "\n",
    ")\n",
    "#print(model.summary())\n",
    "# fit model\n",
    "# if you use data generator use model.fit_generator(...) instead of model.fit(...)\n",
    "# more about `fit_generator` here: https://keras.io/models/sequential/#fit_generator\n",
    "\n",
    "\n",
    "results=model.fit(X_train,y_train,\n",
    "                  batch_size=16,\n",
    "                  epochs=10,\n",
    "                  validation_data=(X_val, y_val),\n",
    "                  verbose = 1,\n",
    "                  callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "f18Up6rVe2j1"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.load_weights('freez.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nzvlABe6hakT"
   },
   "outputs": [],
   "source": [
    "# for layer in model.layers:\n",
    "#     layer.trainable = True\n",
    "# model.compile(\n",
    "#     model.optimizer,\n",
    "#     loss=sm.losses.bce_jaccard_loss,            #I re-assing the original loss function\n",
    "#     metrics=[sm.metrics.iou_score],  #I re-assing the original metric function\n",
    "# #   loss=model.loss,\n",
    "# #   metrics=model.metrics,\n",
    "#     loss_weights=model.loss_weights,\n",
    "#     sample_weight_mode=model.sample_weight_mode,\n",
    "# #    weighted_metrics=model.weighted_metrics,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "OAwYT7p-y_61",
    "outputId": "61a58979-cab8-4f42-9391-9d4fd04c8155"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'loss_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-281d4ce0f758>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# unfreeze encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mset_trainable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# results=model.fit(X_train,y_train,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#                   batch_size=16,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CNN\\lib\\site-packages\\segmentation_models\\utils.py\u001b[0m in \u001b[0;36mset_trainable\u001b[1;34m(model, recompile, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mloss_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[0msample_weight_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_weight_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mweighted_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweighted_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'loss_weights'"
     ]
    }
   ],
   "source": [
    "# unfreeze encoder\n",
    "set_trainable(model)\n",
    "\n",
    "# results=model.fit(X_train,y_train,\n",
    "#                   batch_size=16,\n",
    "#                   epochs=10,\n",
    "#                   validation_data=(X_val, y_val),\n",
    "#                   verbose = 1,\n",
    "#                   callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ov25f-y-y_ye"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optim,\n",
    "    loss=sm.losses.bce_jaccard_loss,\n",
    "    metrics=[sm.metrics.iou_score],\n",
    ")\n",
    "#print(model.summary())\n",
    "# fit model\n",
    "# if you use data generator use model.fit_generator(...) instead of model.fit(...)\n",
    "# more about `fit_generator` here: https://keras.io/models/sequential/#fit_generator\n",
    "\n",
    "\n",
    "results=model.fit(X_train,y_train,\n",
    "                  batch_size=16,\n",
    "                  epochs=100,\n",
    "                  validation_data=(X_val, y_val),\n",
    "                  verbose = 1,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzbSHM3ty_op"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gRKpqGI5hAwy"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logsfreez/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoRklvY7hAsq"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.load_weights('freez.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1eaFszbvhAou",
    "outputId": "3fbacc67-9432-49c6-dc3b-759e32b66fca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 9s 446ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "preds_test_t = (preds_test > 0.3).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mM1DvFijhAgx"
   },
   "outputs": [],
   "source": [
    "preds_test_t = preds_test_t.astype(float)\n",
    "preds_test=preds_test.astype(float)\n",
    "for i in range(len(X_test)):\n",
    "    # print(i)\n",
    "    plt.figure( figsize=(20,3) )\n",
    "    plt.subplot(141)\n",
    "    plt.imshow(X_test[i])\n",
    "    plt.title('Image')\n",
    "    plt.subplot(142)\n",
    "    plt.imshow(Y_test[i])\n",
    "    plt.title('Mask')\n",
    "    plt.subplot(143)\n",
    "    plt.imshow(preds_test_t[i,:,:,0])\n",
    "    plt.title('Prediction')\n",
    "    # plt.title('Prediction. Jaccard coeff: ' + str(np.around(jacard_coef(Y_test[i], preds_test_t[i,:,:,0]), 3)))\n",
    "    # plt.subplot(144)\n",
    "    # plt.imshow(preds_test[i,:,:,0])\n",
    "    # plt.title('no threshold mask. Jaccard coeff: ' + str(np.around(jacard_coef(Y_test[i], preds_test[i,:,:,0]), 3)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FL_viMk8gE-l",
    "outputId": "55982718-543c-4e29-ab3c-118708f8ac91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 241ms/step - loss: 9.7522 - iou_score: 0.0567\n",
      "Accuracy of Jacard Model is =  5.670937895774841 %\n"
     ]
    }
   ],
   "source": [
    "\t# evaluate model\n",
    "_, acc = model.evaluate(X_test, Y_test)\n",
    "print(\"Accuracy of Jacard Model is = \", (acc * 100.0), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bo_qd-JTgE1V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SegmentationResnetbackbonefreeze.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
